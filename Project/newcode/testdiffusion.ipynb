{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "\n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(32 * 8 * 8, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Linear(128, 3 * 32 * 32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = x.view(-1, 3, 32, 32)\n",
    "        return x\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 实例化网络\n",
    "model = DiffusionModel()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 加载数据并划分为训练集、验证集和测试集\n",
    "data = np.load(\"data4D.npy\")\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 将NumPy数组转换为张量\n",
    "train_data_tensor = torch.from_numpy(train_data)\n",
    "val_data_tensor = torch.from_numpy(val_data)\n",
    "test_data_tensor = torch.from_numpy(test_data)\n",
    "\n",
    "# 创建DataLoader\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(train_data_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(val_data_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(test_data_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Step [10/25], Loss: 0.14247357845306396\n",
      "Epoch [1/250], Step [20/25], Loss: 0.058277081698179245\n",
      "Epoch [1/250], Validation Loss: 0.05218342372349331\n",
      "Epoch [2/250], Step [10/25], Loss: 0.05281175300478935\n",
      "Epoch [2/250], Step [20/25], Loss: 0.0505032017827034\n",
      "Epoch [2/250], Validation Loss: 0.05128518545201847\n",
      "Epoch [3/250], Step [10/25], Loss: 0.052752986550331116\n",
      "Epoch [3/250], Step [20/25], Loss: 0.05458296090364456\n",
      "Epoch [3/250], Validation Loss: 0.05084290515099253\n",
      "Epoch [4/250], Step [10/25], Loss: 0.050522156059741974\n",
      "Epoch [4/250], Step [20/25], Loss: 0.05187498778104782\n",
      "Epoch [4/250], Validation Loss: 0.050300018063613346\n",
      "Epoch [5/250], Step [10/25], Loss: 0.04999318718910217\n",
      "Epoch [5/250], Step [20/25], Loss: 0.04962517321109772\n",
      "Epoch [5/250], Validation Loss: 0.04993411526083946\n",
      "Epoch [6/250], Step [10/25], Loss: 0.050143998116254807\n",
      "Epoch [6/250], Step [20/25], Loss: 0.05115341767668724\n",
      "Epoch [6/250], Validation Loss: 0.04971126413771084\n",
      "Epoch [7/250], Step [10/25], Loss: 0.04584973305463791\n",
      "Epoch [7/250], Step [20/25], Loss: 0.05002685636281967\n",
      "Epoch [7/250], Validation Loss: 0.04953965385045324\n",
      "Epoch [8/250], Step [10/25], Loss: 0.04926173388957977\n",
      "Epoch [8/250], Step [20/25], Loss: 0.047100067138671875\n",
      "Epoch [8/250], Validation Loss: 0.04933954456022808\n",
      "Epoch [9/250], Step [10/25], Loss: 0.050262030214071274\n",
      "Epoch [9/250], Step [20/25], Loss: 0.049487706273794174\n",
      "Epoch [9/250], Validation Loss: 0.04909774022442954\n",
      "Epoch [10/250], Step [10/25], Loss: 0.048237144947052\n",
      "Epoch [10/250], Step [20/25], Loss: 0.04963967949151993\n",
      "Epoch [10/250], Validation Loss: 0.04873893729278019\n",
      "Epoch [11/250], Step [10/25], Loss: 0.05077384039759636\n",
      "Epoch [11/250], Step [20/25], Loss: 0.046780239790678024\n",
      "Epoch [11/250], Validation Loss: 0.04839274500097547\n",
      "Epoch [12/250], Step [10/25], Loss: 0.04865230247378349\n",
      "Epoch [12/250], Step [20/25], Loss: 0.04838597774505615\n",
      "Epoch [12/250], Validation Loss: 0.048110214727265496\n",
      "Epoch [13/250], Step [10/25], Loss: 0.050308987498283386\n",
      "Epoch [13/250], Step [20/25], Loss: 0.05162777751684189\n",
      "Epoch [13/250], Validation Loss: 0.047785302358014245\n",
      "Epoch [14/250], Step [10/25], Loss: 0.04719380661845207\n",
      "Epoch [14/250], Step [20/25], Loss: 0.046888675540685654\n",
      "Epoch [14/250], Validation Loss: 0.047550344573599954\n",
      "Epoch [15/250], Step [10/25], Loss: 0.049690328538417816\n",
      "Epoch [15/250], Step [20/25], Loss: 0.04874277114868164\n",
      "Epoch [15/250], Validation Loss: 0.04732704907655716\n",
      "Epoch [16/250], Step [10/25], Loss: 0.048388175666332245\n",
      "Epoch [16/250], Step [20/25], Loss: 0.046593885868787766\n",
      "Epoch [16/250], Validation Loss: 0.04710482859185764\n",
      "Epoch [17/250], Step [10/25], Loss: 0.04804625362157822\n",
      "Epoch [17/250], Step [20/25], Loss: 0.04272909089922905\n",
      "Epoch [17/250], Validation Loss: 0.04701986589602062\n",
      "Epoch [18/250], Step [10/25], Loss: 0.0440257303416729\n",
      "Epoch [18/250], Step [20/25], Loss: 0.04813351854681969\n",
      "Epoch [18/250], Validation Loss: 0.046757906143154414\n",
      "Epoch [19/250], Step [10/25], Loss: 0.044805802404880524\n",
      "Epoch [19/250], Step [20/25], Loss: 0.04804176092147827\n",
      "Epoch [19/250], Validation Loss: 0.046660425407545905\n",
      "Epoch [20/250], Step [10/25], Loss: 0.04802858084440231\n",
      "Epoch [20/250], Step [20/25], Loss: 0.04713667184114456\n",
      "Epoch [20/250], Validation Loss: 0.04645658018333571\n",
      "Epoch [21/250], Step [10/25], Loss: 0.049920305609703064\n",
      "Epoch [21/250], Step [20/25], Loss: 0.04468348249793053\n",
      "Epoch [21/250], Validation Loss: 0.04631024865167482\n",
      "Epoch [22/250], Step [10/25], Loss: 0.04547199606895447\n",
      "Epoch [22/250], Step [20/25], Loss: 0.04780688136816025\n",
      "Epoch [22/250], Validation Loss: 0.04617249593138695\n",
      "Epoch [23/250], Step [10/25], Loss: 0.045788850635290146\n",
      "Epoch [23/250], Step [20/25], Loss: 0.04316268116235733\n",
      "Epoch [23/250], Validation Loss: 0.04593362393123763\n",
      "Epoch [24/250], Step [10/25], Loss: 0.04604855924844742\n",
      "Epoch [24/250], Step [20/25], Loss: 0.047009408473968506\n",
      "Epoch [24/250], Validation Loss: 0.04574443080595562\n",
      "Epoch [25/250], Step [10/25], Loss: 0.04363732039928436\n",
      "Epoch [25/250], Step [20/25], Loss: 0.048450008034706116\n",
      "Epoch [25/250], Validation Loss: 0.04555347615054676\n",
      "Epoch [26/250], Step [10/25], Loss: 0.047366589307785034\n",
      "Epoch [26/250], Step [20/25], Loss: 0.048994503915309906\n",
      "Epoch [26/250], Validation Loss: 0.045436036373887746\n",
      "Epoch [27/250], Step [10/25], Loss: 0.050207894295454025\n",
      "Epoch [27/250], Step [20/25], Loss: 0.04511589929461479\n",
      "Epoch [27/250], Validation Loss: 0.045351311032261164\n",
      "Epoch [28/250], Step [10/25], Loss: 0.04731655865907669\n",
      "Epoch [28/250], Step [20/25], Loss: 0.04557809233665466\n",
      "Epoch [28/250], Validation Loss: 0.04519074356981686\n",
      "Epoch [29/250], Step [10/25], Loss: 0.04684906452894211\n",
      "Epoch [29/250], Step [20/25], Loss: 0.04393883794546127\n",
      "Epoch [29/250], Validation Loss: 0.04555207810231617\n",
      "Epoch [30/250], Step [10/25], Loss: 0.044794075191020966\n",
      "Epoch [30/250], Step [20/25], Loss: 0.04489993676543236\n",
      "Epoch [30/250], Validation Loss: 0.04496140245880399\n",
      "Epoch [31/250], Step [10/25], Loss: 0.04608622193336487\n",
      "Epoch [31/250], Step [20/25], Loss: 0.04435039311647415\n",
      "Epoch [31/250], Validation Loss: 0.04477731032030923\n",
      "Epoch [32/250], Step [10/25], Loss: 0.04462463781237602\n",
      "Epoch [32/250], Step [20/25], Loss: 0.04131920635700226\n",
      "Epoch [32/250], Validation Loss: 0.04467206395098141\n",
      "Epoch [33/250], Step [10/25], Loss: 0.04537420719861984\n",
      "Epoch [33/250], Step [20/25], Loss: 0.04464435577392578\n",
      "Epoch [33/250], Validation Loss: 0.04457090528947966\n",
      "Epoch [34/250], Step [10/25], Loss: 0.04613601788878441\n",
      "Epoch [34/250], Step [20/25], Loss: 0.043541353195905685\n",
      "Epoch [34/250], Validation Loss: 0.04445624298283032\n",
      "Epoch [35/250], Step [10/25], Loss: 0.04224444925785065\n",
      "Epoch [35/250], Step [20/25], Loss: 0.04785561561584473\n",
      "Epoch [35/250], Validation Loss: 0.04426513931580952\n",
      "Epoch [36/250], Step [10/25], Loss: 0.04251626878976822\n",
      "Epoch [36/250], Step [20/25], Loss: 0.042841847985982895\n",
      "Epoch [36/250], Validation Loss: 0.04413241520524025\n",
      "Epoch [37/250], Step [10/25], Loss: 0.04767398163676262\n",
      "Epoch [37/250], Step [20/25], Loss: 0.04719298332929611\n",
      "Epoch [37/250], Validation Loss: 0.04400014025824411\n",
      "Epoch [38/250], Step [10/25], Loss: 0.04272463172674179\n",
      "Epoch [38/250], Step [20/25], Loss: 0.04434330761432648\n",
      "Epoch [38/250], Validation Loss: 0.043875632009335926\n",
      "Epoch [39/250], Step [10/25], Loss: 0.046256523579359055\n",
      "Epoch [39/250], Step [20/25], Loss: 0.04690420627593994\n",
      "Epoch [39/250], Validation Loss: 0.043752585138593404\n",
      "Epoch [40/250], Step [10/25], Loss: 0.04026639088988304\n",
      "Epoch [40/250], Step [20/25], Loss: 0.04652960225939751\n",
      "Epoch [40/250], Validation Loss: 0.043558113276958466\n",
      "Epoch [41/250], Step [10/25], Loss: 0.045840367674827576\n",
      "Epoch [41/250], Step [20/25], Loss: 0.044138193130493164\n",
      "Epoch [41/250], Validation Loss: 0.04341508341687066\n",
      "Epoch [42/250], Step [10/25], Loss: 0.04392921179533005\n",
      "Epoch [42/250], Step [20/25], Loss: 0.042957887053489685\n",
      "Epoch [42/250], Validation Loss: 0.043408105948141644\n",
      "Epoch [43/250], Step [10/25], Loss: 0.04239111393690109\n",
      "Epoch [43/250], Step [20/25], Loss: 0.04387979209423065\n",
      "Epoch [43/250], Validation Loss: 0.0430816901581628\n",
      "Epoch [44/250], Step [10/25], Loss: 0.04363328218460083\n",
      "Epoch [44/250], Step [20/25], Loss: 0.04151848703622818\n",
      "Epoch [44/250], Validation Loss: 0.04289476786340986\n",
      "Epoch [45/250], Step [10/25], Loss: 0.04261884093284607\n",
      "Epoch [45/250], Step [20/25], Loss: 0.042786769568920135\n",
      "Epoch [45/250], Validation Loss: 0.04283235275319645\n",
      "Epoch [46/250], Step [10/25], Loss: 0.04758688062429428\n",
      "Epoch [46/250], Step [20/25], Loss: 0.04103449359536171\n",
      "Epoch [46/250], Validation Loss: 0.04263879092676299\n",
      "Epoch [47/250], Step [10/25], Loss: 0.04037543386220932\n",
      "Epoch [47/250], Step [20/25], Loss: 0.04518022760748863\n",
      "Epoch [47/250], Validation Loss: 0.04251611764941897\n",
      "Epoch [48/250], Step [10/25], Loss: 0.03962397202849388\n",
      "Epoch [48/250], Step [20/25], Loss: 0.04073195904493332\n",
      "Epoch [48/250], Validation Loss: 0.04231784386294229\n",
      "Epoch [49/250], Step [10/25], Loss: 0.03991423547267914\n",
      "Epoch [49/250], Step [20/25], Loss: 0.039342090487480164\n",
      "Epoch [49/250], Validation Loss: 0.04229116226945605\n",
      "Epoch [50/250], Step [10/25], Loss: 0.04168200492858887\n",
      "Epoch [50/250], Step [20/25], Loss: 0.04058216139674187\n",
      "Epoch [50/250], Validation Loss: 0.042303217841046195\n",
      "Epoch [51/250], Step [10/25], Loss: 0.0448966920375824\n",
      "Epoch [51/250], Step [20/25], Loss: 0.038646623492240906\n",
      "Epoch [51/250], Validation Loss: 0.04201013914176396\n",
      "Epoch [52/250], Step [10/25], Loss: 0.04243895411491394\n",
      "Epoch [52/250], Step [20/25], Loss: 0.039979252964258194\n",
      "Epoch [52/250], Validation Loss: 0.04179616538541658\n",
      "Epoch [53/250], Step [10/25], Loss: 0.040907688438892365\n",
      "Epoch [53/250], Step [20/25], Loss: 0.04270925372838974\n",
      "Epoch [53/250], Validation Loss: 0.04160406014748982\n",
      "Epoch [54/250], Step [10/25], Loss: 0.04375417158007622\n",
      "Epoch [54/250], Step [20/25], Loss: 0.04378857463598251\n",
      "Epoch [54/250], Validation Loss: 0.04143749496766499\n",
      "Epoch [55/250], Step [10/25], Loss: 0.046246375888586044\n",
      "Epoch [55/250], Step [20/25], Loss: 0.0398562029004097\n",
      "Epoch [55/250], Validation Loss: 0.04130632962499346\n",
      "Epoch [56/250], Step [10/25], Loss: 0.04226137697696686\n",
      "Epoch [56/250], Step [20/25], Loss: 0.042266279458999634\n",
      "Epoch [56/250], Validation Loss: 0.04115226971251624\n",
      "Epoch [57/250], Step [10/25], Loss: 0.038630127906799316\n",
      "Epoch [57/250], Step [20/25], Loss: 0.04150537773966789\n",
      "Epoch [57/250], Validation Loss: 0.04108112784368651\n",
      "Epoch [58/250], Step [10/25], Loss: 0.04150552675127983\n",
      "Epoch [58/250], Step [20/25], Loss: 0.04015883803367615\n",
      "Epoch [58/250], Validation Loss: 0.04085547210914748\n",
      "Epoch [59/250], Step [10/25], Loss: 0.038440901786088943\n",
      "Epoch [59/250], Step [20/25], Loss: 0.042831432074308395\n",
      "Epoch [59/250], Validation Loss: 0.04073518514633179\n",
      "Epoch [60/250], Step [10/25], Loss: 0.04133759066462517\n",
      "Epoch [60/250], Step [20/25], Loss: 0.03943228721618652\n",
      "Epoch [60/250], Validation Loss: 0.04061306108321462\n",
      "Epoch [61/250], Step [10/25], Loss: 0.04168320819735527\n",
      "Epoch [61/250], Step [20/25], Loss: 0.04079262912273407\n",
      "Epoch [61/250], Validation Loss: 0.04046352473752839\n",
      "Epoch [62/250], Step [10/25], Loss: 0.04265200346708298\n",
      "Epoch [62/250], Step [20/25], Loss: 0.03943600505590439\n",
      "Epoch [62/250], Validation Loss: 0.04042344593576023\n",
      "Epoch [63/250], Step [10/25], Loss: 0.04079192876815796\n",
      "Epoch [63/250], Step [20/25], Loss: 0.04146333038806915\n",
      "Epoch [63/250], Validation Loss: 0.04020762390324047\n",
      "Epoch [64/250], Step [10/25], Loss: 0.03968527168035507\n",
      "Epoch [64/250], Step [20/25], Loss: 0.044319283217191696\n",
      "Epoch [64/250], Validation Loss: 0.04008972644805908\n",
      "Epoch [65/250], Step [10/25], Loss: 0.04090343043208122\n",
      "Epoch [65/250], Step [20/25], Loss: 0.03968309611082077\n",
      "Epoch [65/250], Validation Loss: 0.03995478206447193\n",
      "Epoch [66/250], Step [10/25], Loss: 0.03985804319381714\n",
      "Epoch [66/250], Step [20/25], Loss: 0.042934857308864594\n",
      "Epoch [66/250], Validation Loss: 0.039855893701314926\n",
      "Epoch [67/250], Step [10/25], Loss: 0.03770432248711586\n",
      "Epoch [67/250], Step [20/25], Loss: 0.04105556756258011\n",
      "Epoch [67/250], Validation Loss: 0.03982345813087055\n",
      "Epoch [68/250], Step [10/25], Loss: 0.037847183644771576\n",
      "Epoch [68/250], Step [20/25], Loss: 0.0384858101606369\n",
      "Epoch [68/250], Validation Loss: 0.039805923721620014\n",
      "Epoch [69/250], Step [10/25], Loss: 0.041888706386089325\n",
      "Epoch [69/250], Step [20/25], Loss: 0.038447361439466476\n",
      "Epoch [69/250], Validation Loss: 0.03967957038964544\n",
      "Epoch [70/250], Step [10/25], Loss: 0.04022497683763504\n",
      "Epoch [70/250], Step [20/25], Loss: 0.039048608392477036\n",
      "Epoch [70/250], Validation Loss: 0.039490356509174616\n",
      "Epoch [71/250], Step [10/25], Loss: 0.040539830923080444\n",
      "Epoch [71/250], Step [20/25], Loss: 0.03874706104397774\n",
      "Epoch [71/250], Validation Loss: 0.03955474921635219\n",
      "Epoch [72/250], Step [10/25], Loss: 0.03480244427919388\n",
      "Epoch [72/250], Step [20/25], Loss: 0.03716970980167389\n",
      "Epoch [72/250], Validation Loss: 0.039290758648089\n",
      "Epoch [73/250], Step [10/25], Loss: 0.03998643904924393\n",
      "Epoch [73/250], Step [20/25], Loss: 0.0390683189034462\n",
      "Epoch [73/250], Validation Loss: 0.03922479120748384\n",
      "Epoch [74/250], Step [10/25], Loss: 0.037475138902664185\n",
      "Epoch [74/250], Step [20/25], Loss: 0.04144507274031639\n",
      "Epoch [74/250], Validation Loss: 0.03916403491582189\n",
      "Epoch [75/250], Step [10/25], Loss: 0.0382605642080307\n",
      "Epoch [75/250], Step [20/25], Loss: 0.037476226687431335\n",
      "Epoch [75/250], Validation Loss: 0.0390655653817313\n",
      "Epoch [76/250], Step [10/25], Loss: 0.035727258771657944\n",
      "Epoch [76/250], Step [20/25], Loss: 0.03830321505665779\n",
      "Epoch [76/250], Validation Loss: 0.03914953023195267\n",
      "Epoch [77/250], Step [10/25], Loss: 0.03858300298452377\n",
      "Epoch [77/250], Step [20/25], Loss: 0.036748021841049194\n",
      "Epoch [77/250], Validation Loss: 0.038938314254794805\n",
      "Epoch [78/250], Step [10/25], Loss: 0.03768545016646385\n",
      "Epoch [78/250], Step [20/25], Loss: 0.03733252361416817\n",
      "Epoch [78/250], Validation Loss: 0.03881136753729412\n",
      "Epoch [79/250], Step [10/25], Loss: 0.03742511197924614\n",
      "Epoch [79/250], Step [20/25], Loss: 0.03851024806499481\n",
      "Epoch [79/250], Validation Loss: 0.03876658635480063\n",
      "Epoch [80/250], Step [10/25], Loss: 0.03937096521258354\n",
      "Epoch [80/250], Step [20/25], Loss: 0.0427851602435112\n",
      "Epoch [80/250], Validation Loss: 0.03870357360158648\n",
      "Epoch [81/250], Step [10/25], Loss: 0.03784303367137909\n",
      "Epoch [81/250], Step [20/25], Loss: 0.03887399286031723\n",
      "Epoch [81/250], Validation Loss: 0.03865564561315945\n",
      "Epoch [82/250], Step [10/25], Loss: 0.03949665650725365\n",
      "Epoch [82/250], Step [20/25], Loss: 0.04264039546251297\n",
      "Epoch [82/250], Validation Loss: 0.0386531555226871\n",
      "Epoch [83/250], Step [10/25], Loss: 0.039558276534080505\n",
      "Epoch [83/250], Step [20/25], Loss: 0.04190194606781006\n",
      "Epoch [83/250], Validation Loss: 0.0385272242128849\n",
      "Epoch [84/250], Step [10/25], Loss: 0.039013322442770004\n",
      "Epoch [84/250], Step [20/25], Loss: 0.035485513508319855\n",
      "Epoch [84/250], Validation Loss: 0.03842410498431751\n",
      "Epoch [85/250], Step [10/25], Loss: 0.038266297429800034\n",
      "Epoch [85/250], Step [20/25], Loss: 0.03853418678045273\n",
      "Epoch [85/250], Validation Loss: 0.038394219641174586\n",
      "Epoch [86/250], Step [10/25], Loss: 0.038498587906360626\n",
      "Epoch [86/250], Step [20/25], Loss: 0.038316816091537476\n",
      "Epoch [86/250], Validation Loss: 0.038414645940065384\n",
      "Epoch [87/250], Step [10/25], Loss: 0.038974858820438385\n",
      "Epoch [87/250], Step [20/25], Loss: 0.037814632058143616\n",
      "Epoch [87/250], Validation Loss: 0.038273650620664866\n",
      "Epoch [88/250], Step [10/25], Loss: 0.03680654987692833\n",
      "Epoch [88/250], Step [20/25], Loss: 0.03860916942358017\n",
      "Epoch [88/250], Validation Loss: 0.03820477958236422\n",
      "Epoch [89/250], Step [10/25], Loss: 0.03847856819629669\n",
      "Epoch [89/250], Step [20/25], Loss: 0.041081272065639496\n",
      "Epoch [89/250], Validation Loss: 0.03810283328805651\n",
      "Epoch [90/250], Step [10/25], Loss: 0.03865120932459831\n",
      "Epoch [90/250], Step [20/25], Loss: 0.0376877561211586\n",
      "Epoch [90/250], Validation Loss: 0.03803645872644016\n",
      "Epoch [91/250], Step [10/25], Loss: 0.03783521056175232\n",
      "Epoch [91/250], Step [20/25], Loss: 0.03957624360918999\n",
      "Epoch [91/250], Validation Loss: 0.0380313369844641\n",
      "Epoch [92/250], Step [10/25], Loss: 0.03659244626760483\n",
      "Epoch [92/250], Step [20/25], Loss: 0.03615500032901764\n",
      "Epoch [92/250], Validation Loss: 0.03796173312834331\n",
      "Epoch [93/250], Step [10/25], Loss: 0.03538781404495239\n",
      "Epoch [93/250], Step [20/25], Loss: 0.036351174116134644\n",
      "Epoch [93/250], Validation Loss: 0.03791424046669688\n",
      "Epoch [94/250], Step [10/25], Loss: 0.03858865797519684\n",
      "Epoch [94/250], Step [20/25], Loss: 0.03712984547019005\n",
      "Epoch [94/250], Validation Loss: 0.03784493463379996\n",
      "Epoch [95/250], Step [10/25], Loss: 0.03711105138063431\n",
      "Epoch [95/250], Step [20/25], Loss: 0.03953506052494049\n",
      "Epoch [95/250], Validation Loss: 0.03789642293538366\n",
      "Epoch [96/250], Step [10/25], Loss: 0.03281683474779129\n",
      "Epoch [96/250], Step [20/25], Loss: 0.03869015723466873\n",
      "Epoch [96/250], Validation Loss: 0.03784746304154396\n",
      "Epoch [97/250], Step [10/25], Loss: 0.03661233186721802\n",
      "Epoch [97/250], Step [20/25], Loss: 0.03757769614458084\n",
      "Epoch [97/250], Validation Loss: 0.03767034358211926\n",
      "Epoch [98/250], Step [10/25], Loss: 0.036836083978414536\n",
      "Epoch [98/250], Step [20/25], Loss: 0.03473474830389023\n",
      "Epoch [98/250], Validation Loss: 0.037635424839598794\n",
      "Epoch [99/250], Step [10/25], Loss: 0.04126278683543205\n",
      "Epoch [99/250], Step [20/25], Loss: 0.03667542338371277\n",
      "Epoch [99/250], Validation Loss: 0.03776328265666962\n",
      "Epoch [100/250], Step [10/25], Loss: 0.03777865320444107\n",
      "Epoch [100/250], Step [20/25], Loss: 0.03800905868411064\n",
      "Epoch [100/250], Validation Loss: 0.03765663185289928\n",
      "Epoch [101/250], Step [10/25], Loss: 0.038121454417705536\n",
      "Epoch [101/250], Step [20/25], Loss: 0.038941219449043274\n",
      "Epoch [101/250], Validation Loss: 0.037568313734872\n",
      "Epoch [102/250], Step [10/25], Loss: 0.03937587887048721\n",
      "Epoch [102/250], Step [20/25], Loss: 0.03971550986170769\n",
      "Epoch [102/250], Validation Loss: 0.03748335210340364\n",
      "Epoch [103/250], Step [10/25], Loss: 0.0372815765440464\n",
      "Epoch [103/250], Step [20/25], Loss: 0.03908265754580498\n",
      "Epoch [103/250], Validation Loss: 0.037474051650081365\n",
      "Epoch [104/250], Step [10/25], Loss: 0.036763500422239304\n",
      "Epoch [104/250], Step [20/25], Loss: 0.0377066433429718\n",
      "Epoch [104/250], Validation Loss: 0.03750782726066453\n",
      "Epoch [105/250], Step [10/25], Loss: 0.03831775486469269\n",
      "Epoch [105/250], Step [20/25], Loss: 0.03650017827749252\n",
      "Epoch [105/250], Validation Loss: 0.037501511829239983\n",
      "Epoch [106/250], Step [10/25], Loss: 0.03531120344996452\n",
      "Epoch [106/250], Step [20/25], Loss: 0.03783752769231796\n",
      "Epoch [106/250], Validation Loss: 0.037389492349965234\n",
      "Epoch [107/250], Step [10/25], Loss: 0.038008809089660645\n",
      "Epoch [107/250], Step [20/25], Loss: 0.03730727359652519\n",
      "Epoch [107/250], Validation Loss: 0.03732908996088164\n",
      "Epoch [108/250], Step [10/25], Loss: 0.037730611860752106\n",
      "Epoch [108/250], Step [20/25], Loss: 0.03833121061325073\n",
      "Epoch [108/250], Validation Loss: 0.03746121110660689\n",
      "Epoch [109/250], Step [10/25], Loss: 0.03640873730182648\n",
      "Epoch [109/250], Step [20/25], Loss: 0.038399651646614075\n",
      "Epoch [109/250], Validation Loss: 0.03748305195144245\n",
      "Epoch [110/250], Step [10/25], Loss: 0.0352138951420784\n",
      "Epoch [110/250], Step [20/25], Loss: 0.037285588681697845\n",
      "Epoch [110/250], Validation Loss: 0.037230529955455234\n",
      "Epoch [111/250], Step [10/25], Loss: 0.03630808740854263\n",
      "Epoch [111/250], Step [20/25], Loss: 0.03896825760602951\n",
      "Epoch [111/250], Validation Loss: 0.037261693073170524\n",
      "Epoch [112/250], Step [10/25], Loss: 0.03689674660563469\n",
      "Epoch [112/250], Step [20/25], Loss: 0.038767486810684204\n",
      "Epoch [112/250], Validation Loss: 0.03715292204703603\n",
      "Epoch [113/250], Step [10/25], Loss: 0.03739034757018089\n",
      "Epoch [113/250], Step [20/25], Loss: 0.03458204120397568\n",
      "Epoch [113/250], Validation Loss: 0.03712312451430729\n",
      "Epoch [114/250], Step [10/25], Loss: 0.03425433859229088\n",
      "Epoch [114/250], Step [20/25], Loss: 0.03653034567832947\n",
      "Epoch [114/250], Validation Loss: 0.03713542755161013\n",
      "Epoch [115/250], Step [10/25], Loss: 0.03692907840013504\n",
      "Epoch [115/250], Step [20/25], Loss: 0.03688004985451698\n",
      "Epoch [115/250], Validation Loss: 0.0371107565505164\n",
      "Epoch [116/250], Step [10/25], Loss: 0.036353252828121185\n",
      "Epoch [116/250], Step [20/25], Loss: 0.03910335153341293\n",
      "Epoch [116/250], Validation Loss: 0.03706135866897447\n",
      "Epoch [117/250], Step [10/25], Loss: 0.038288287818431854\n",
      "Epoch [117/250], Step [20/25], Loss: 0.03753449395298958\n",
      "Epoch [117/250], Validation Loss: 0.03722560352512768\n",
      "Epoch [118/250], Step [10/25], Loss: 0.03693738579750061\n",
      "Epoch [118/250], Step [20/25], Loss: 0.03393413871526718\n",
      "Epoch [118/250], Validation Loss: 0.036975322025162835\n",
      "Epoch [119/250], Step [10/25], Loss: 0.03703125938773155\n",
      "Epoch [119/250], Step [20/25], Loss: 0.03611604496836662\n",
      "Epoch [119/250], Validation Loss: 0.036919661930629184\n",
      "Epoch [120/250], Step [10/25], Loss: 0.03583619371056557\n",
      "Epoch [120/250], Step [20/25], Loss: 0.03624328598380089\n",
      "Epoch [120/250], Validation Loss: 0.03693909464137895\n",
      "Epoch [121/250], Step [10/25], Loss: 0.03459106385707855\n",
      "Epoch [121/250], Step [20/25], Loss: 0.0364011749625206\n",
      "Epoch [121/250], Validation Loss: 0.037078781319516044\n",
      "Epoch [122/250], Step [10/25], Loss: 0.03861101716756821\n",
      "Epoch [122/250], Step [20/25], Loss: 0.0310562402009964\n",
      "Epoch [122/250], Validation Loss: 0.03688844985195568\n",
      "Epoch [123/250], Step [10/25], Loss: 0.034443199634552\n",
      "Epoch [123/250], Step [20/25], Loss: 0.03688850253820419\n",
      "Epoch [123/250], Validation Loss: 0.03691381588578224\n",
      "Epoch [124/250], Step [10/25], Loss: 0.03476434201002121\n",
      "Epoch [124/250], Step [20/25], Loss: 0.03850295767188072\n",
      "Epoch [124/250], Validation Loss: 0.03682611882686615\n",
      "Epoch [125/250], Step [10/25], Loss: 0.03512877970933914\n",
      "Epoch [125/250], Step [20/25], Loss: 0.035428956151008606\n",
      "Epoch [125/250], Validation Loss: 0.036745191152606695\n",
      "Epoch [126/250], Step [10/25], Loss: 0.03309119865298271\n",
      "Epoch [126/250], Step [20/25], Loss: 0.03779736906290054\n",
      "Epoch [126/250], Validation Loss: 0.03683896628873689\n",
      "Epoch [127/250], Step [10/25], Loss: 0.03834552690386772\n",
      "Epoch [127/250], Step [20/25], Loss: 0.03694452345371246\n",
      "Epoch [127/250], Validation Loss: 0.03675069447074618\n",
      "Epoch [128/250], Step [10/25], Loss: 0.036482661962509155\n",
      "Epoch [128/250], Step [20/25], Loss: 0.035646140575408936\n",
      "Epoch [128/250], Validation Loss: 0.03686490495290075\n",
      "Epoch [129/250], Step [10/25], Loss: 0.03337056189775467\n",
      "Epoch [129/250], Step [20/25], Loss: 0.0361168347299099\n",
      "Epoch [129/250], Validation Loss: 0.03683489773954664\n",
      "Epoch [130/250], Step [10/25], Loss: 0.034762389957904816\n",
      "Epoch [130/250], Step [20/25], Loss: 0.04046107083559036\n",
      "Epoch [130/250], Validation Loss: 0.036853546010596414\n",
      "Epoch [131/250], Step [10/25], Loss: 0.036306604743003845\n",
      "Epoch [131/250], Step [20/25], Loss: 0.036583151668310165\n",
      "Epoch [131/250], Validation Loss: 0.03662887162395886\n",
      "Epoch [132/250], Step [10/25], Loss: 0.036947816610336304\n",
      "Epoch [132/250], Step [20/25], Loss: 0.03570106625556946\n",
      "Epoch [132/250], Validation Loss: 0.03672159942133086\n",
      "Epoch [133/250], Step [10/25], Loss: 0.03641700744628906\n",
      "Epoch [133/250], Step [20/25], Loss: 0.040456339716911316\n",
      "Epoch [133/250], Validation Loss: 0.03678818419575691\n",
      "Epoch [134/250], Step [10/25], Loss: 0.03183511272072792\n",
      "Epoch [134/250], Step [20/25], Loss: 0.0359947644174099\n",
      "Epoch [134/250], Validation Loss: 0.03665867767163685\n",
      "Epoch [135/250], Step [10/25], Loss: 0.03732982277870178\n",
      "Epoch [135/250], Step [20/25], Loss: 0.037458598613739014\n",
      "Epoch [135/250], Validation Loss: 0.036575189126389365\n",
      "Epoch [136/250], Step [10/25], Loss: 0.03589247912168503\n",
      "Epoch [136/250], Step [20/25], Loss: 0.03639062121510506\n",
      "Epoch [136/250], Validation Loss: 0.03660031993474279\n",
      "Epoch [137/250], Step [10/25], Loss: 0.037189122289419174\n",
      "Epoch [137/250], Step [20/25], Loss: 0.03848844766616821\n",
      "Epoch [137/250], Validation Loss: 0.036836265453270504\n",
      "Epoch [138/250], Step [10/25], Loss: 0.039217136800289154\n",
      "Epoch [138/250], Step [20/25], Loss: 0.03554797172546387\n",
      "Epoch [138/250], Validation Loss: 0.03663006744214466\n",
      "Epoch [139/250], Step [10/25], Loss: 0.03644762560725212\n",
      "Epoch [139/250], Step [20/25], Loss: 0.03627999126911163\n",
      "Epoch [139/250], Validation Loss: 0.03665676712989807\n",
      "Epoch [140/250], Step [10/25], Loss: 0.036750294268131256\n",
      "Epoch [140/250], Step [20/25], Loss: 0.037185054272413254\n",
      "Epoch [140/250], Validation Loss: 0.03658886839236532\n",
      "Epoch [141/250], Step [10/25], Loss: 0.0356539711356163\n",
      "Epoch [141/250], Step [20/25], Loss: 0.037198349833488464\n",
      "Epoch [141/250], Validation Loss: 0.036471148154565265\n",
      "Epoch [142/250], Step [10/25], Loss: 0.03536025434732437\n",
      "Epoch [142/250], Step [20/25], Loss: 0.035476744174957275\n",
      "Epoch [142/250], Validation Loss: 0.036628482065030506\n",
      "Epoch [143/250], Step [10/25], Loss: 0.036764901131391525\n",
      "Epoch [143/250], Step [20/25], Loss: 0.033757396042346954\n",
      "Epoch [143/250], Validation Loss: 0.03657977442656245\n",
      "Epoch [144/250], Step [10/25], Loss: 0.0341583713889122\n",
      "Epoch [144/250], Step [20/25], Loss: 0.03429746255278587\n",
      "Epoch [144/250], Validation Loss: 0.036489688392196386\n",
      "Epoch [145/250], Step [10/25], Loss: 0.03538917750120163\n",
      "Epoch [145/250], Step [20/25], Loss: 0.035444777458906174\n",
      "Epoch [145/250], Validation Loss: 0.036437938788107464\n",
      "Epoch [146/250], Step [10/25], Loss: 0.03679251670837402\n",
      "Epoch [146/250], Step [20/25], Loss: 0.037245012819767\n",
      "Epoch [146/250], Validation Loss: 0.036422904048647196\n",
      "Epoch [147/250], Step [10/25], Loss: 0.03598726913332939\n",
      "Epoch [147/250], Step [20/25], Loss: 0.032454963773489\n",
      "Epoch [147/250], Validation Loss: 0.03641175851225853\n",
      "Epoch [148/250], Step [10/25], Loss: 0.03575194999575615\n",
      "Epoch [148/250], Step [20/25], Loss: 0.033009931445121765\n",
      "Epoch [148/250], Validation Loss: 0.03645216567175729\n",
      "Epoch [149/250], Step [10/25], Loss: 0.0327962189912796\n",
      "Epoch [149/250], Step [20/25], Loss: 0.03989729285240173\n",
      "Epoch [149/250], Validation Loss: 0.036467784217425754\n",
      "Epoch [150/250], Step [10/25], Loss: 0.03700311481952667\n",
      "Epoch [150/250], Step [20/25], Loss: 0.034170981496572495\n",
      "Epoch [150/250], Validation Loss: 0.03639284308467593\n",
      "Epoch [151/250], Step [10/25], Loss: 0.0363476499915123\n",
      "Epoch [151/250], Step [20/25], Loss: 0.037125762552022934\n",
      "Epoch [151/250], Validation Loss: 0.03646814024874142\n",
      "Epoch [152/250], Step [10/25], Loss: 0.03673979640007019\n",
      "Epoch [152/250], Step [20/25], Loss: 0.035905566066503525\n",
      "Epoch [152/250], Validation Loss: 0.036406087556055615\n",
      "Epoch [153/250], Step [10/25], Loss: 0.03725876659154892\n",
      "Epoch [153/250], Step [20/25], Loss: 0.03586050495505333\n",
      "Epoch [153/250], Validation Loss: 0.03641302191785404\n",
      "Epoch [154/250], Step [10/25], Loss: 0.03420516848564148\n",
      "Epoch [154/250], Step [20/25], Loss: 0.03722664341330528\n",
      "Epoch [154/250], Validation Loss: 0.03629828563758305\n",
      "Epoch [155/250], Step [10/25], Loss: 0.037905462086200714\n",
      "Epoch [155/250], Step [20/25], Loss: 0.03891804814338684\n",
      "Epoch [155/250], Validation Loss: 0.03627395470227514\n",
      "Epoch [156/250], Step [10/25], Loss: 0.03333555907011032\n",
      "Epoch [156/250], Step [20/25], Loss: 0.038228802382946014\n",
      "Epoch [156/250], Validation Loss: 0.03633008152246475\n",
      "Epoch [157/250], Step [10/25], Loss: 0.036988839507102966\n",
      "Epoch [157/250], Step [20/25], Loss: 0.03584560751914978\n",
      "Epoch [157/250], Validation Loss: 0.03630970684545381\n",
      "Epoch [158/250], Step [10/25], Loss: 0.03371763229370117\n",
      "Epoch [158/250], Step [20/25], Loss: 0.03605843335390091\n",
      "Epoch [158/250], Validation Loss: 0.03629730535405023\n",
      "Epoch [159/250], Step [10/25], Loss: 0.037831518799066544\n",
      "Epoch [159/250], Step [20/25], Loss: 0.03825884684920311\n",
      "Epoch [159/250], Validation Loss: 0.03622346105320113\n",
      "Epoch [160/250], Step [10/25], Loss: 0.03476373106241226\n",
      "Epoch [160/250], Step [20/25], Loss: 0.035325437784194946\n",
      "Epoch [160/250], Validation Loss: 0.03629201437745776\n",
      "Epoch [161/250], Step [10/25], Loss: 0.03417900577187538\n",
      "Epoch [161/250], Step [20/25], Loss: 0.03515898436307907\n",
      "Epoch [161/250], Validation Loss: 0.03625095635652542\n",
      "Epoch [162/250], Step [10/25], Loss: 0.03572900965809822\n",
      "Epoch [162/250], Step [20/25], Loss: 0.03375988453626633\n",
      "Epoch [162/250], Validation Loss: 0.036207813769578934\n",
      "Epoch [163/250], Step [10/25], Loss: 0.0363382026553154\n",
      "Epoch [163/250], Step [20/25], Loss: 0.0371897891163826\n",
      "Epoch [163/250], Validation Loss: 0.036229747746671946\n",
      "Epoch [164/250], Step [10/25], Loss: 0.03453835844993591\n",
      "Epoch [164/250], Step [20/25], Loss: 0.03164657950401306\n",
      "Epoch [164/250], Validation Loss: 0.03625827921288354\n",
      "Epoch [165/250], Step [10/25], Loss: 0.036545880138874054\n",
      "Epoch [165/250], Step [20/25], Loss: 0.036541324108839035\n",
      "Epoch [165/250], Validation Loss: 0.036271648215396066\n",
      "Epoch [166/250], Step [10/25], Loss: 0.038207169622182846\n",
      "Epoch [166/250], Step [20/25], Loss: 0.03631780669093132\n",
      "Epoch [166/250], Validation Loss: 0.03626388683915138\n",
      "Epoch [167/250], Step [10/25], Loss: 0.03529579937458038\n",
      "Epoch [167/250], Step [20/25], Loss: 0.036122143268585205\n",
      "Epoch [167/250], Validation Loss: 0.03619887839470591\n",
      "Epoch [168/250], Step [10/25], Loss: 0.03822045028209686\n",
      "Epoch [168/250], Step [20/25], Loss: 0.036795374006032944\n",
      "Epoch [168/250], Validation Loss: 0.036232619413307736\n",
      "Epoch [169/250], Step [10/25], Loss: 0.03565601631999016\n",
      "Epoch [169/250], Step [20/25], Loss: 0.03481646999716759\n",
      "Epoch [169/250], Validation Loss: 0.03630600816437176\n",
      "Epoch [170/250], Step [10/25], Loss: 0.03807833045721054\n",
      "Epoch [170/250], Step [20/25], Loss: 0.03538680076599121\n",
      "Epoch [170/250], Validation Loss: 0.036202495119401386\n",
      "Epoch [171/250], Step [10/25], Loss: 0.03481694310903549\n",
      "Epoch [171/250], Step [20/25], Loss: 0.03522579371929169\n",
      "Epoch [171/250], Validation Loss: 0.03614547795483044\n",
      "Epoch [172/250], Step [10/25], Loss: 0.03786603733897209\n",
      "Epoch [172/250], Step [20/25], Loss: 0.03581902012228966\n",
      "Epoch [172/250], Validation Loss: 0.03613767506820815\n",
      "Epoch [173/250], Step [10/25], Loss: 0.03535415232181549\n",
      "Epoch [173/250], Step [20/25], Loss: 0.03758741542696953\n",
      "Epoch [173/250], Validation Loss: 0.03608845493623188\n",
      "Epoch [174/250], Step [10/25], Loss: 0.038213178515434265\n",
      "Epoch [174/250], Step [20/25], Loss: 0.037948306649923325\n",
      "Epoch [174/250], Validation Loss: 0.03615598167691912\n",
      "Epoch [175/250], Step [10/25], Loss: 0.03879765793681145\n",
      "Epoch [175/250], Step [20/25], Loss: 0.03708004206418991\n",
      "Epoch [175/250], Validation Loss: 0.03613479967628207\n",
      "Epoch [176/250], Step [10/25], Loss: 0.03653192147612572\n",
      "Epoch [176/250], Step [20/25], Loss: 0.03608417883515358\n",
      "Epoch [176/250], Validation Loss: 0.036114846489259174\n",
      "Epoch [177/250], Step [10/25], Loss: 0.03921034187078476\n",
      "Epoch [177/250], Step [20/25], Loss: 0.038242556154727936\n",
      "Epoch [177/250], Validation Loss: 0.03626118653586933\n",
      "Epoch [178/250], Step [10/25], Loss: 0.033254027366638184\n",
      "Epoch [178/250], Step [20/25], Loss: 0.03659965097904205\n",
      "Epoch [178/250], Validation Loss: 0.036061850509473255\n",
      "Epoch [179/250], Step [10/25], Loss: 0.037175845354795456\n",
      "Epoch [179/250], Step [20/25], Loss: 0.03510589897632599\n",
      "Epoch [179/250], Validation Loss: 0.03607861325144768\n",
      "Epoch [180/250], Step [10/25], Loss: 0.036114566028118134\n",
      "Epoch [180/250], Step [20/25], Loss: 0.03765805810689926\n",
      "Epoch [180/250], Validation Loss: 0.03604664387447493\n",
      "Epoch [181/250], Step [10/25], Loss: 0.038913190364837646\n",
      "Epoch [181/250], Step [20/25], Loss: 0.035595476627349854\n",
      "Epoch [181/250], Validation Loss: 0.03615965907062803\n",
      "Epoch [182/250], Step [10/25], Loss: 0.03659413382411003\n",
      "Epoch [182/250], Step [20/25], Loss: 0.035628970712423325\n",
      "Epoch [182/250], Validation Loss: 0.03604329058102199\n",
      "Epoch [183/250], Step [10/25], Loss: 0.03702953830361366\n",
      "Epoch [183/250], Step [20/25], Loss: 0.035442717373371124\n",
      "Epoch [183/250], Validation Loss: 0.0360101472054209\n",
      "Epoch [184/250], Step [10/25], Loss: 0.03649424761533737\n",
      "Epoch [184/250], Step [20/25], Loss: 0.03585324436426163\n",
      "Epoch [184/250], Validation Loss: 0.036020666893039434\n",
      "Epoch [185/250], Step [10/25], Loss: 0.03633235767483711\n",
      "Epoch [185/250], Step [20/25], Loss: 0.036431342363357544\n",
      "Epoch [185/250], Validation Loss: 0.03601183369755745\n",
      "Epoch [186/250], Step [10/25], Loss: 0.03452366590499878\n",
      "Epoch [186/250], Step [20/25], Loss: 0.03552136570215225\n",
      "Epoch [186/250], Validation Loss: 0.03606269934347698\n",
      "Epoch [187/250], Step [10/25], Loss: 0.04041917622089386\n",
      "Epoch [187/250], Step [20/25], Loss: 0.03565660119056702\n",
      "Epoch [187/250], Validation Loss: 0.036070602280753\n",
      "Epoch [188/250], Step [10/25], Loss: 0.035600319504737854\n",
      "Epoch [188/250], Step [20/25], Loss: 0.036153413355350494\n",
      "Epoch [188/250], Validation Loss: 0.036083243255104334\n",
      "Epoch [189/250], Step [10/25], Loss: 0.03667575120925903\n",
      "Epoch [189/250], Step [20/25], Loss: 0.03372149169445038\n",
      "Epoch [189/250], Validation Loss: 0.035974684570516856\n",
      "Epoch [190/250], Step [10/25], Loss: 0.03895210474729538\n",
      "Epoch [190/250], Step [20/25], Loss: 0.03811882808804512\n",
      "Epoch [190/250], Validation Loss: 0.03600013522165162\n",
      "Epoch [191/250], Step [10/25], Loss: 0.030299706384539604\n",
      "Epoch [191/250], Step [20/25], Loss: 0.03401493281126022\n",
      "Epoch [191/250], Validation Loss: 0.03610627938594137\n",
      "Epoch [192/250], Step [10/25], Loss: 0.03655222803354263\n",
      "Epoch [192/250], Step [20/25], Loss: 0.03429551050066948\n",
      "Epoch [192/250], Validation Loss: 0.035970735762800486\n",
      "Epoch [193/250], Step [10/25], Loss: 0.03362446650862694\n",
      "Epoch [193/250], Step [20/25], Loss: 0.03688695654273033\n",
      "Epoch [193/250], Validation Loss: 0.03599632531404495\n",
      "Epoch [194/250], Step [10/25], Loss: 0.0340842679142952\n",
      "Epoch [194/250], Step [20/25], Loss: 0.034211598336696625\n",
      "Epoch [194/250], Validation Loss: 0.03600003251007625\n",
      "Epoch [195/250], Step [10/25], Loss: 0.036736905574798584\n",
      "Epoch [195/250], Step [20/25], Loss: 0.03785891830921173\n",
      "Epoch [195/250], Validation Loss: 0.03620089537331036\n",
      "Epoch [196/250], Step [10/25], Loss: 0.03438029810786247\n",
      "Epoch [196/250], Step [20/25], Loss: 0.033924125134944916\n",
      "Epoch [196/250], Validation Loss: 0.03599788195320538\n",
      "Epoch [197/250], Step [10/25], Loss: 0.03354528173804283\n",
      "Epoch [197/250], Step [20/25], Loss: 0.036413490772247314\n",
      "Epoch [197/250], Validation Loss: 0.036004584814820974\n",
      "Epoch [198/250], Step [10/25], Loss: 0.0360955186188221\n",
      "Epoch [198/250], Step [20/25], Loss: 0.03606187179684639\n",
      "Epoch [198/250], Validation Loss: 0.03589520177670887\n",
      "Epoch [199/250], Step [10/25], Loss: 0.03748593479394913\n",
      "Epoch [199/250], Step [20/25], Loss: 0.03565772995352745\n",
      "Epoch [199/250], Validation Loss: 0.035931025232587545\n",
      "Epoch [200/250], Step [10/25], Loss: 0.03553757816553116\n",
      "Epoch [200/250], Step [20/25], Loss: 0.035178277641534805\n",
      "Epoch [200/250], Validation Loss: 0.03595568612217903\n",
      "Epoch [201/250], Step [10/25], Loss: 0.03752170130610466\n",
      "Epoch [201/250], Step [20/25], Loss: 0.036847665905952454\n",
      "Epoch [201/250], Validation Loss: 0.035880091467073986\n",
      "Epoch [202/250], Step [10/25], Loss: 0.03998823091387749\n",
      "Epoch [202/250], Step [20/25], Loss: 0.033601660281419754\n",
      "Epoch [202/250], Validation Loss: 0.03592194616794586\n",
      "Epoch [203/250], Step [10/25], Loss: 0.037315528839826584\n",
      "Epoch [203/250], Step [20/25], Loss: 0.03402281552553177\n",
      "Epoch [203/250], Validation Loss: 0.035969459052596776\n",
      "Epoch [204/250], Step [10/25], Loss: 0.03570267930626869\n",
      "Epoch [204/250], Step [20/25], Loss: 0.036447614431381226\n",
      "Epoch [204/250], Validation Loss: 0.03588733822107315\n",
      "Epoch [205/250], Step [10/25], Loss: 0.03333846852183342\n",
      "Epoch [205/250], Step [20/25], Loss: 0.03486833721399307\n",
      "Epoch [205/250], Validation Loss: 0.03585061856678554\n",
      "Epoch [206/250], Step [10/25], Loss: 0.03497101366519928\n",
      "Epoch [206/250], Step [20/25], Loss: 0.03734281659126282\n",
      "Epoch [206/250], Validation Loss: 0.03595626513872828\n",
      "Epoch [207/250], Step [10/25], Loss: 0.03766698017716408\n",
      "Epoch [207/250], Step [20/25], Loss: 0.03102961555123329\n",
      "Epoch [207/250], Validation Loss: 0.03581585043243\n",
      "Epoch [208/250], Step [10/25], Loss: 0.03655204921960831\n",
      "Epoch [208/250], Step [20/25], Loss: 0.036745499819517136\n",
      "Epoch [208/250], Validation Loss: 0.035819667258432934\n",
      "Epoch [209/250], Step [10/25], Loss: 0.03449041396379471\n",
      "Epoch [209/250], Step [20/25], Loss: 0.035500891506671906\n",
      "Epoch [209/250], Validation Loss: 0.035903388900416236\n",
      "Epoch [210/250], Step [10/25], Loss: 0.03605855256319046\n",
      "Epoch [210/250], Step [20/25], Loss: 0.03610774874687195\n",
      "Epoch [210/250], Validation Loss: 0.03590968410883631\n",
      "Epoch [211/250], Step [10/25], Loss: 0.03220386430621147\n",
      "Epoch [211/250], Step [20/25], Loss: 0.032511159777641296\n",
      "Epoch [211/250], Validation Loss: 0.035842577793768475\n",
      "Epoch [212/250], Step [10/25], Loss: 0.037292540073394775\n",
      "Epoch [212/250], Step [20/25], Loss: 0.03503796458244324\n",
      "Epoch [212/250], Validation Loss: 0.03582669794559479\n",
      "Epoch [213/250], Step [10/25], Loss: 0.03695325925946236\n",
      "Epoch [213/250], Step [20/25], Loss: 0.03465378284454346\n",
      "Epoch [213/250], Validation Loss: 0.03582297584840229\n",
      "Epoch [214/250], Step [10/25], Loss: 0.03486911579966545\n",
      "Epoch [214/250], Step [20/25], Loss: 0.0345742404460907\n",
      "Epoch [214/250], Validation Loss: 0.03581917073045458\n",
      "Epoch [215/250], Step [10/25], Loss: 0.03482171893119812\n",
      "Epoch [215/250], Step [20/25], Loss: 0.03276580572128296\n",
      "Epoch [215/250], Validation Loss: 0.035793698259762356\n",
      "Epoch [216/250], Step [10/25], Loss: 0.03255290538072586\n",
      "Epoch [216/250], Step [20/25], Loss: 0.037157751619815826\n",
      "Epoch [216/250], Validation Loss: 0.0357970047209944\n",
      "Epoch [217/250], Step [10/25], Loss: 0.031801220029592514\n",
      "Epoch [217/250], Step [20/25], Loss: 0.037290506064891815\n",
      "Epoch [217/250], Validation Loss: 0.0358082540333271\n",
      "Epoch [218/250], Step [10/25], Loss: 0.035775620490312576\n",
      "Epoch [218/250], Step [20/25], Loss: 0.03715236112475395\n",
      "Epoch [218/250], Validation Loss: 0.0358520687690803\n",
      "Epoch [219/250], Step [10/25], Loss: 0.03729211539030075\n",
      "Epoch [219/250], Step [20/25], Loss: 0.035515353083610535\n",
      "Epoch [219/250], Validation Loss: 0.035837053188255856\n",
      "Epoch [220/250], Step [10/25], Loss: 0.04061519727110863\n",
      "Epoch [220/250], Step [20/25], Loss: 0.03808637708425522\n",
      "Epoch [220/250], Validation Loss: 0.03580729610153607\n",
      "Epoch [221/250], Step [10/25], Loss: 0.033273302018642426\n",
      "Epoch [221/250], Step [20/25], Loss: 0.03680271655321121\n",
      "Epoch [221/250], Validation Loss: 0.03583383826272828\n",
      "Epoch [222/250], Step [10/25], Loss: 0.03642916679382324\n",
      "Epoch [222/250], Step [20/25], Loss: 0.037293240427970886\n",
      "Epoch [222/250], Validation Loss: 0.035794075046266825\n",
      "Epoch [223/250], Step [10/25], Loss: 0.035362422466278076\n",
      "Epoch [223/250], Step [20/25], Loss: 0.03724534064531326\n",
      "Epoch [223/250], Validation Loss: 0.03575346406017031\n",
      "Epoch [224/250], Step [10/25], Loss: 0.03641899675130844\n",
      "Epoch [224/250], Step [20/25], Loss: 0.03651724010705948\n",
      "Epoch [224/250], Validation Loss: 0.035732124000787735\n",
      "Epoch [225/250], Step [10/25], Loss: 0.036688774824142456\n",
      "Epoch [225/250], Step [20/25], Loss: 0.03764701634645462\n",
      "Epoch [225/250], Validation Loss: 0.03588073860321726\n",
      "Epoch [226/250], Step [10/25], Loss: 0.03468184173107147\n",
      "Epoch [226/250], Step [20/25], Loss: 0.03810979425907135\n",
      "Epoch [226/250], Validation Loss: 0.035885843847479136\n",
      "Epoch [227/250], Step [10/25], Loss: 0.03479601442813873\n",
      "Epoch [227/250], Step [20/25], Loss: 0.035711050033569336\n",
      "Epoch [227/250], Validation Loss: 0.035756652908665795\n",
      "Epoch [228/250], Step [10/25], Loss: 0.03458407148718834\n",
      "Epoch [228/250], Step [20/25], Loss: 0.03631040081381798\n",
      "Epoch [228/250], Validation Loss: 0.0357568295938628\n",
      "Epoch [229/250], Step [10/25], Loss: 0.033416103571653366\n",
      "Epoch [229/250], Step [20/25], Loss: 0.03649541735649109\n",
      "Epoch [229/250], Validation Loss: 0.035816358136279244\n",
      "Epoch [230/250], Step [10/25], Loss: 0.033287934958934784\n",
      "Epoch [230/250], Step [20/25], Loss: 0.03738681226968765\n",
      "Epoch [230/250], Validation Loss: 0.03570528594510896\n",
      "Epoch [231/250], Step [10/25], Loss: 0.03812215477228165\n",
      "Epoch [231/250], Step [20/25], Loss: 0.03353661298751831\n",
      "Epoch [231/250], Validation Loss: 0.03574613854289055\n",
      "Epoch [232/250], Step [10/25], Loss: 0.03337937220931053\n",
      "Epoch [232/250], Step [20/25], Loss: 0.03707611560821533\n",
      "Epoch [232/250], Validation Loss: 0.03577003415141787\n",
      "Epoch [233/250], Step [10/25], Loss: 0.03740428760647774\n",
      "Epoch [233/250], Step [20/25], Loss: 0.03464215621352196\n",
      "Epoch [233/250], Validation Loss: 0.0357028990983963\n",
      "Epoch [234/250], Step [10/25], Loss: 0.03425569087266922\n",
      "Epoch [234/250], Step [20/25], Loss: 0.032483264803886414\n",
      "Epoch [234/250], Validation Loss: 0.03577241940157754\n",
      "Epoch [235/250], Step [10/25], Loss: 0.03745521977543831\n",
      "Epoch [235/250], Step [20/25], Loss: 0.03379354625940323\n",
      "Epoch [235/250], Validation Loss: 0.03578182043773787\n",
      "Epoch [236/250], Step [10/25], Loss: 0.03721555322408676\n",
      "Epoch [236/250], Step [20/25], Loss: 0.040135473012924194\n",
      "Epoch [236/250], Validation Loss: 0.03565448682223048\n",
      "Epoch [237/250], Step [10/25], Loss: 0.034242626279592514\n",
      "Epoch [237/250], Step [20/25], Loss: 0.03773807734251022\n",
      "Epoch [237/250], Validation Loss: 0.035618457411016734\n",
      "Epoch [238/250], Step [10/25], Loss: 0.03555670380592346\n",
      "Epoch [238/250], Step [20/25], Loss: 0.0318569615483284\n",
      "Epoch [238/250], Validation Loss: 0.035676295203822\n",
      "Epoch [239/250], Step [10/25], Loss: 0.03365126997232437\n",
      "Epoch [239/250], Step [20/25], Loss: 0.03578650951385498\n",
      "Epoch [239/250], Validation Loss: 0.03586706625563758\n",
      "Epoch [240/250], Step [10/25], Loss: 0.03472511097788811\n",
      "Epoch [240/250], Step [20/25], Loss: 0.03416658937931061\n",
      "Epoch [240/250], Validation Loss: 0.03570045477577618\n",
      "Epoch [241/250], Step [10/25], Loss: 0.033552393317222595\n",
      "Epoch [241/250], Step [20/25], Loss: 0.037724968045949936\n",
      "Epoch [241/250], Validation Loss: 0.03569017191018377\n",
      "Epoch [242/250], Step [10/25], Loss: 0.0351925827562809\n",
      "Epoch [242/250], Step [20/25], Loss: 0.03570623695850372\n",
      "Epoch [242/250], Validation Loss: 0.03562979559813227\n",
      "Epoch [243/250], Step [10/25], Loss: 0.034624092280864716\n",
      "Epoch [243/250], Step [20/25], Loss: 0.036891110241413116\n",
      "Epoch [243/250], Validation Loss: 0.03583866783550808\n",
      "Epoch [244/250], Step [10/25], Loss: 0.033849991858005524\n",
      "Epoch [244/250], Step [20/25], Loss: 0.037586528807878494\n",
      "Epoch [244/250], Validation Loss: 0.03561316004821232\n",
      "Epoch [245/250], Step [10/25], Loss: 0.03744369372725487\n",
      "Epoch [245/250], Step [20/25], Loss: 0.03495415672659874\n",
      "Epoch [245/250], Validation Loss: 0.03560933257852282\n",
      "Epoch [246/250], Step [10/25], Loss: 0.033399924635887146\n",
      "Epoch [246/250], Step [20/25], Loss: 0.03462814539670944\n",
      "Epoch [246/250], Validation Loss: 0.035630788654088974\n",
      "Epoch [247/250], Step [10/25], Loss: 0.034818150103092194\n",
      "Epoch [247/250], Step [20/25], Loss: 0.03325546160340309\n",
      "Epoch [247/250], Validation Loss: 0.035774871174778254\n",
      "Epoch [248/250], Step [10/25], Loss: 0.03549015522003174\n",
      "Epoch [248/250], Step [20/25], Loss: 0.03631892055273056\n",
      "Epoch [248/250], Validation Loss: 0.035614004624741416\n",
      "Epoch [249/250], Step [10/25], Loss: 0.03570791333913803\n",
      "Epoch [249/250], Step [20/25], Loss: 0.03314491733908653\n",
      "Epoch [249/250], Validation Loss: 0.03563204460910389\n",
      "Epoch [250/250], Step [10/25], Loss: 0.03601614758372307\n",
      "Epoch [250/250], Step [20/25], Loss: 0.03614033758640289\n",
      "Epoch [250/250], Validation Loss: 0.03556521024022784\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 250\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DiffusionModel().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        inputs = data[0].to(device)\n",
    "        targets = data[0].to(device) # 为了重构输入，使用输入数据作为目标数据\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item()}')\n",
    "\n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader):\n",
    "            inputs = data[0].to(device)\n",
    "            targets = data[0].to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss/len(val_loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0356166479177773\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        inputs = data[0].to(device)\n",
    "        targets = data[0].to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "print(f'Test Loss: {test_loss/len(test_loader)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}