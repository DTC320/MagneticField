{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import yaml\n",
    "import shutil\n",
    "from yaml.loader import SafeLoader\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions as td\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from netAE import AE\n",
    "from netVAE import VAE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "path_yaml  = \"config.yaml\"\n",
    "\n",
    "#config = yaml.load(path_yaml,Loader=SafeLoader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(5000, 3, 32, 32)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"data4D.npy\", allow_pickle= True)\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Trainset/testset\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 将NumPy数组转换为张量\n",
    "train_data_tensor = torch.from_numpy(train_data)\n",
    "test_data_tensor = torch.from_numpy(test_data)\n",
    "\n",
    "# 创建DataLoader\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(train_data_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_data_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, img_channels, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # 编码器\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # 获取编码器的输出大小\n",
    "        self.encoder_output_size = self.encoder(torch.zeros(1, img_channels, 32, 32)).shape[1]\n",
    "\n",
    "        # 计算均值和对数方差\n",
    "        self.fc_mu = nn.Linear(self.encoder_output_size, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.encoder_output_size, latent_dim)\n",
    "\n",
    "        # 解码器\n",
    "        self.fc_decode = nn.Linear(latent_dim, self.encoder_output_size)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (128, 4, 4)),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, img_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = self.fc_mu(h), self.fc_logvar(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(self.fc_decode(z))\n",
    "        return x_recon, mu, logvar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def vae_loss(x, x_recon, mu, logvar):\n",
    "    recon_loss = nn.functional.mse_loss(x_recon, x, reduction='sum') / x.size(0)\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "    return recon_loss + kl_div"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "img_channels = 3\n",
    "latent_dim = 128\n",
    "model = VAE(img_channels, latent_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 3.2395\n",
      "====> Epoch: 2 Average loss: 1.3518\n",
      "====> Epoch: 3 Average loss: 1.3372\n",
      "====> Epoch: 4 Average loss: 1.3373\n",
      "====> Epoch: 5 Average loss: 1.3263\n",
      "====> Epoch: 6 Average loss: 1.3258\n",
      "====> Epoch: 7 Average loss: 1.3200\n",
      "====> Epoch: 8 Average loss: 1.3240\n",
      "====> Epoch: 9 Average loss: 1.3227\n",
      "====> Epoch: 10 Average loss: 1.3154\n",
      "====> Epoch: 11 Average loss: 1.3174\n",
      "====> Epoch: 12 Average loss: 1.3194\n",
      "====> Epoch: 13 Average loss: 1.3154\n",
      "====> Epoch: 14 Average loss: 1.3137\n",
      "====> Epoch: 15 Average loss: 1.3133\n",
      "====> Epoch: 16 Average loss: 1.3093\n",
      "====> Epoch: 17 Average loss: 1.3048\n",
      "====> Epoch: 18 Average loss: 1.3003\n",
      "====> Epoch: 19 Average loss: 1.2967\n",
      "====> Epoch: 20 Average loss: 1.2919\n",
      "====> Epoch: 21 Average loss: 1.2875\n",
      "====> Epoch: 22 Average loss: 1.2889\n",
      "====> Epoch: 23 Average loss: 1.2917\n",
      "====> Epoch: 24 Average loss: 1.2945\n",
      "====> Epoch: 25 Average loss: 1.2896\n",
      "====> Epoch: 26 Average loss: 1.2876\n",
      "====> Epoch: 27 Average loss: 1.2896\n",
      "====> Epoch: 28 Average loss: 1.2869\n",
      "====> Epoch: 29 Average loss: 1.2909\n",
      "====> Epoch: 30 Average loss: 1.2841\n",
      "====> Epoch: 31 Average loss: 1.2886\n",
      "====> Epoch: 32 Average loss: 1.2863\n",
      "====> Epoch: 33 Average loss: 1.2850\n",
      "====> Epoch: 34 Average loss: 1.2860\n",
      "====> Epoch: 35 Average loss: 1.2910\n",
      "====> Epoch: 36 Average loss: 1.2901\n",
      "====> Epoch: 37 Average loss: 1.2889\n",
      "====> Epoch: 38 Average loss: 1.2873\n",
      "====> Epoch: 39 Average loss: 1.2889\n",
      "====> Epoch: 40 Average loss: 1.2880\n",
      "====> Epoch: 41 Average loss: 1.2919\n",
      "====> Epoch: 42 Average loss: 1.2862\n",
      "====> Epoch: 43 Average loss: 1.2902\n",
      "====> Epoch: 44 Average loss: 1.2848\n",
      "====> Epoch: 45 Average loss: 1.2887\n",
      "====> Epoch: 46 Average loss: 1.2962\n",
      "====> Epoch: 47 Average loss: 1.2891\n",
      "====> Epoch: 48 Average loss: 1.2902\n",
      "====> Epoch: 49 Average loss: 1.2901\n",
      "====> Epoch: 50 Average loss: 1.2875\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "# TRAIN\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (data,) in enumerate(train_loader):\n",
    "        data = data.float()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = vae_loss(data, recon_batch, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch + 1, train_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.2608\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (data,) in enumerate(test_loader):\n",
    "        data = data.float()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += vae_loss(data, recon_batch, mu, logvar).item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('====> Test set loss: {:.4f}'.format(test_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}